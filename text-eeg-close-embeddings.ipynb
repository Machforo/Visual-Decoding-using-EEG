{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9994575,"sourceType":"datasetVersion","datasetId":6151473}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''        \n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:55:37.393414Z","iopub.execute_input":"2024-11-23T20:55:37.393774Z","iopub.status.idle":"2024-11-23T20:55:38.716553Z","shell.execute_reply.started":"2024-11-23T20:55:37.393742Z","shell.execute_reply":"2024-11-23T20:55:38.715394Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"############################## Using CLIP model to bring EEG embeddings and Text Embeddings Closer #####################################\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm  # For progress bars\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load and normalize embeddings\neeg_embeddings = np.load('/kaggle/input/embeddings/eeg_embeddings.npy')\ntext_embeddings = np.load('/kaggle/input/embeddings/generated_captions_embeddings.npy')\n\n# Normalize embeddings\neeg_embeddings = torch.tensor(eeg_embeddings / np.linalg.norm(eeg_embeddings, axis=1, keepdims=True), dtype=torch.float32)\ntext_embeddings = torch.tensor(text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True), dtype=torch.float32)\n\n# Transfer embeddings to GPU\neeg_embeddings = eeg_embeddings.to(device)\ntext_embeddings = text_embeddings.to(device)\n\n# Create dataset and dataloader\ndataset = TensorDataset(eeg_embeddings, text_embeddings)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n\n# Define CLIP-like model\nclass CLIPModel(nn.Module):\n    def __init__(self, eeg_dim, text_dim, projection_dim):\n        super(CLIPModel, self).__init__()\n        self.eeg_encoder = nn.Linear(eeg_dim, projection_dim)\n        self.text_encoder = nn.Linear(text_dim, projection_dim)\n\n    def forward(self, eeg, text):\n        eeg_proj = self.eeg_encoder(eeg)\n        text_proj = self.text_encoder(text)\n        return eeg_proj, text_proj\n\n# Loss function: Contrastive loss\ndef contrastive_loss(eeg_proj, text_proj, temperature=0.07):\n    logits = torch.matmul(eeg_proj, text_proj.T) / temperature\n    labels = torch.arange(logits.size(0)).to(logits.device)\n    loss_eeg = nn.CrossEntropyLoss()(logits, labels)\n    loss_text = nn.CrossEntropyLoss()(logits.T, labels)\n    return (loss_eeg + loss_text) / 2\n\n# Model, optimizer, and training setup\neeg_dim = eeg_embeddings.size(1)\ntext_dim = text_embeddings.size(1)\nprojection_dim = 512\nmodel = CLIPModel(eeg_dim, text_dim, projection_dim).to(device)  # Transfer model to GPU\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Training loop with progress monitoring\nepochs = 20\nmodel.train()\nfor epoch in range(epochs):\n    epoch_loss = 0\n    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\") as progress_bar:\n        for eeg_batch, text_batch in progress_bar:\n            optimizer.zero_grad()\n            eeg_proj, text_proj = model(eeg_batch, text_batch)\n            loss = contrastive_loss(eeg_proj, text_proj)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {epoch_loss / len(dataloader):.4f}\")\n\n# Save modified embeddings\nmodel.eval()\nmodified_eeg_embeddings = []\nmodified_text_embeddings = []\nwith torch.no_grad():\n    with tqdm(dataloader, desc=\"Generating Modified Embeddings\") as progress_bar:\n        for eeg_batch, text_batch in progress_bar:\n            eeg_proj, text_proj = model(eeg_batch, text_batch)\n            modified_eeg_embeddings.append(eeg_proj.cpu())\n            modified_text_embeddings.append(text_proj.cpu())\n\n# Combine and save embeddings\nmodified_eeg_embeddings = torch.cat(modified_eeg_embeddings, dim=0).numpy()\nmodified_text_embeddings = torch.cat(modified_text_embeddings, dim=0).numpy()\n\nnp.save('modified_eeg_embeddings.npy', modified_eeg_embeddings)\nnp.save('modified_text_embeddings.npy', modified_text_embeddings)\n\nprint(\"Modified embeddings saved!\")\n\n####################################################################################################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T21:14:40.875625Z","iopub.execute_input":"2024-11-23T21:14:40.876232Z","iopub.status.idle":"2024-11-23T21:14:58.481885Z","shell.execute_reply.started":"2024-11-23T21:14:40.876196Z","shell.execute_reply":"2024-11-23T21:14:58.481009Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 259/259 [00:00<00:00, 300.35it/s, Batch Loss=3.6] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Average Loss: 4.4892\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 259/259 [00:00<00:00, 312.80it/s, Batch Loss=3.66]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Average Loss: 4.2536\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 259/259 [00:00<00:00, 315.09it/s, Batch Loss=3.62]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Average Loss: 4.1603\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 259/259 [00:00<00:00, 307.51it/s, Batch Loss=3.35]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Average Loss: 4.0978\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 259/259 [00:00<00:00, 305.01it/s, Batch Loss=3.36]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Average Loss: 4.0522\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 259/259 [00:00<00:00, 305.72it/s, Batch Loss=3.21]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Average Loss: 4.0230\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 259/259 [00:00<00:00, 311.21it/s, Batch Loss=3.17]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Average Loss: 3.9993\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 259/259 [00:00<00:00, 309.02it/s, Batch Loss=2.98]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Average Loss: 3.9850\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|██████████| 259/259 [00:00<00:00, 296.47it/s, Batch Loss=3.22]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Average Loss: 3.9703\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|██████████| 259/259 [00:00<00:00, 271.23it/s, Batch Loss=3.22]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Average Loss: 3.9622\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|██████████| 259/259 [00:00<00:00, 283.52it/s, Batch Loss=3.08]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Average Loss: 3.9536\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|██████████| 259/259 [00:00<00:00, 306.61it/s, Batch Loss=3.13]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Average Loss: 3.9487\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20: 100%|██████████| 259/259 [00:00<00:00, 306.76it/s, Batch Loss=3.06]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Average Loss: 3.9452\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20: 100%|██████████| 259/259 [00:00<00:00, 301.44it/s, Batch Loss=3.04]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Average Loss: 3.9390\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20: 100%|██████████| 259/259 [00:00<00:00, 296.73it/s, Batch Loss=3.14]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Average Loss: 3.9376\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20: 100%|██████████| 259/259 [00:00<00:00, 300.42it/s, Batch Loss=3.11]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Average Loss: 3.9343\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20: 100%|██████████| 259/259 [00:00<00:00, 301.69it/s, Batch Loss=3.04]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Average Loss: 3.9288\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20: 100%|██████████| 259/259 [00:00<00:00, 300.97it/s, Batch Loss=3.45]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Average Loss: 3.9286\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20: 100%|██████████| 259/259 [00:00<00:00, 303.57it/s, Batch Loss=3.3] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Average Loss: 3.9273\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20: 100%|██████████| 259/259 [00:00<00:00, 306.36it/s, Batch Loss=3.26]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Average Loss: 3.9195\n","output_type":"stream"},{"name":"stderr","text":"Generating Modified Embeddings: 100%|██████████| 259/259 [00:00<00:00, 1153.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Modified embeddings saved!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"############################## Using CLIP model to bring EEG embeddings and Text Embeddings Closer( for vae only )#####################################\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm  # For progress bars\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load and normalize embeddings\neeg_embeddings = np.load('/kaggle/input/embeddings/eeg_embeddings.npy')\ntext_embeddings = np.load('/kaggle/input/embeddings/generated_captions_vae_embeddings.npy')\n\n# Normalize embeddings\neeg_embeddings = torch.tensor(eeg_embeddings / np.linalg.norm(eeg_embeddings, axis=1, keepdims=True), dtype=torch.float32)\ntext_embeddings = torch.tensor(text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True), dtype=torch.float32)\n\n# Transfer embeddings to GPU\neeg_embeddings = eeg_embeddings.to(device)\ntext_embeddings = text_embeddings.to(device)\n\n# Create dataset and dataloader\ndataset = TensorDataset(eeg_embeddings, text_embeddings)\ndataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n\n# Define CLIP-like model\nclass CLIPModel(nn.Module):\n    def __init__(self, eeg_dim, text_dim, projection_dim):\n        super(CLIPModel, self).__init__()\n        self.eeg_encoder = nn.Linear(eeg_dim, projection_dim)\n        self.text_encoder = nn.Linear(text_dim, projection_dim)\n\n    def forward(self, eeg, text):\n        eeg_proj = self.eeg_encoder(eeg)\n        text_proj = self.text_encoder(text)\n        return eeg_proj, text_proj\n\n# Loss function: Contrastive loss\ndef contrastive_loss(eeg_proj, text_proj, temperature=0.07):\n    logits = torch.matmul(eeg_proj, text_proj.T) / temperature\n    labels = torch.arange(logits.size(0)).to(logits.device)\n    loss_eeg = nn.CrossEntropyLoss()(logits, labels)\n    loss_text = nn.CrossEntropyLoss()(logits.T, labels)\n    return (loss_eeg + loss_text) / 2\n\n# Model, optimizer, and training setup\neeg_dim = eeg_embeddings.size(1)\ntext_dim = text_embeddings.size(1)\nprojection_dim = 512\nmodel = CLIPModel(eeg_dim, text_dim, projection_dim).to(device)  # Transfer model to GPU\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Training loop with progress monitoring\nepochs = 20\nmodel.train()\nfor epoch in range(epochs):\n    epoch_loss = 0\n    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\") as progress_bar:\n        for eeg_batch, text_batch in progress_bar:\n            optimizer.zero_grad()\n            eeg_proj, text_proj = model(eeg_batch, text_batch)\n            loss = contrastive_loss(eeg_proj, text_proj)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {epoch_loss / len(dataloader):.4f}\")\n\n# Save modified embeddings\nmodel.eval()\nmodified_eeg_embeddings = []\nmodified_text_embeddings = []\nwith torch.no_grad():\n    with tqdm(dataloader, desc=\"Generating Modified Embeddings\") as progress_bar:\n        for eeg_batch, text_batch in progress_bar:\n            eeg_proj, text_proj = model(eeg_batch, text_batch)\n            modified_eeg_embeddings.append(eeg_proj.cpu())\n            modified_text_embeddings.append(text_proj.cpu())\n\n# Combine and save embeddings\nmodified_eeg_embeddings = torch.cat(modified_eeg_embeddings, dim=0).numpy()\nmodified_text_embeddings = torch.cat(modified_text_embeddings, dim=0).numpy()\n\nnp.save('modified_eeg_vae_embeddings.npy', modified_eeg_embeddings)\nnp.save('modified_text_vae_embeddings.npy', modified_text_embeddings)\n\nprint(\"Modified embeddings saved!\")\n\n####################################################################################################################################","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T21:15:17.515725Z","iopub.execute_input":"2024-11-23T21:15:17.516108Z","iopub.status.idle":"2024-11-23T21:15:34.393245Z","shell.execute_reply.started":"2024-11-23T21:15:17.516075Z","shell.execute_reply":"2024-11-23T21:15:34.392415Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 259/259 [00:00<00:00, 323.14it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Average Loss: 4.2304\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 259/259 [00:00<00:00, 324.94it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 259/259 [00:00<00:00, 312.44it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 259/259 [00:00<00:00, 262.43it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 259/259 [00:00<00:00, 292.56it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Average Loss: 4.2273\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 259/259 [00:00<00:00, 315.60it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 259/259 [00:00<00:00, 319.07it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 259/259 [00:00<00:00, 325.41it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|██████████| 259/259 [00:00<00:00, 326.95it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|██████████| 259/259 [00:00<00:00, 320.95it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|██████████| 259/259 [00:00<00:00, 317.98it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|██████████| 259/259 [00:00<00:00, 297.99it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20: 100%|██████████| 259/259 [00:00<00:00, 325.65it/s, Batch Loss=3.34]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Average Loss: 4.1811\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20: 100%|██████████| 259/259 [00:00<00:00, 319.62it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Average Loss: 4.1572\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20: 100%|██████████| 259/259 [00:00<00:00, 324.67it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20: 100%|██████████| 259/259 [00:00<00:00, 308.22it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Average Loss: 4.1557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20: 100%|██████████| 259/259 [00:00<00:00, 316.65it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Average Loss: 4.1559\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20: 100%|██████████| 259/259 [00:00<00:00, 321.11it/s, Batch Loss=3.34]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Average Loss: 4.1645\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20: 100%|██████████| 259/259 [00:00<00:00, 322.93it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Average Loss: 4.1573\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20: 100%|██████████| 259/259 [00:00<00:00, 323.62it/s, Batch Loss=3.33]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Average Loss: 4.1561\n","output_type":"stream"},{"name":"stderr","text":"Generating Modified Embeddings: 100%|██████████| 259/259 [00:00<00:00, 1154.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Modified embeddings saved!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"'''\nThe case 1 embeddings avaerage loss is lesser so using that only \n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T21:16:06.777891Z","iopub.execute_input":"2024-11-23T21:16:06.778986Z","iopub.status.idle":"2024-11-23T21:16:06.784964Z","shell.execute_reply.started":"2024-11-23T21:16:06.778949Z","shell.execute_reply":"2024-11-23T21:16:06.784212Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\nThe case 1 embeddings avaerage loss is lesser so using that only \\n'"},"metadata":{}}],"execution_count":9}]}