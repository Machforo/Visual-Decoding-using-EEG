{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9994417,"sourceType":"datasetVersion","datasetId":6151359}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:28:12.840089Z","iopub.execute_input":"2024-11-23T20:28:12.840409Z","iopub.status.idle":"2024-11-23T20:28:14.027407Z","shell.execute_reply.started":"2024-11-23T20:28:12.840379Z","shell.execute_reply":"2024-11-23T20:28:14.026436Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"\"\\nimport os\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:29:04.951557Z","iopub.execute_input":"2024-11-23T20:29:04.952311Z","iopub.status.idle":"2024-11-23T20:29:15.097029Z","shell.execute_reply.started":"2024-11-23T20:29:04.952279Z","shell.execute_reply":"2024-11-23T20:29:15.095884Z"}},"outputs":[{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.25.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.3.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nfrom sentence_transformers import SentenceTransformer\n\n# Load the generated captions\ncaptions = np.load('/kaggle/input/generated-captions/generated_captions.npy', allow_pickle=True)\n\n# Initialize the Sentence-BERT model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')  # A fast and efficient model\n\n# Generate embeddings for all captions\ncaptions_embeddings = model.encode(captions, show_progress_bar=True)\n\n# Save the generated embeddings as a numpy array\nnp.save('generated_captions_embeddings.npy', captions_embeddings)\n\n# Print the shape of the embeddings\nprint(f\"Generated captions embeddings shape: {captions_embeddings.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:30:26.090904Z","iopub.execute_input":"2024-11-23T20:30:26.091266Z","iopub.status.idle":"2024-11-23T20:30:30.969767Z","shell.execute_reply.started":"2024-11-23T20:30:26.091235Z","shell.execute_reply":"2024-11-23T20:30:30.968840Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/517 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3730590d348b4bbab4a92e175adfe514"}},"metadata":{}},{"name":"stdout","text":"Generated captions embeddings shape: (16540, 384)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom transformers import BertTokenizer\nfrom tqdm import tqdm\nimport numpy as np\n\n# Define the VAE Architecture for Text\nclass VAEText(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, latent_dim, hidden_dim, seq_length):\n        super(VAEText, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n        self.fc_decode = nn.Linear(latent_dim, hidden_dim)\n        self.rnn_decode = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n        self.seq_length = seq_length\n\n    def encode(self, x):\n        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n        _, (hidden, _) = self.rnn(x)  # hidden: (1, batch_size, hidden_dim)\n        hidden = hidden[-1]  # (batch_size, hidden_dim)\n        mu = self.fc_mu(hidden)  # (batch_size, latent_dim)\n        logvar = self.fc_logvar(hidden)  # (batch_size, latent_dim)\n        return mu, logvar\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        z = self.fc_decode(z)  # (batch_size, hidden_dim)\n        z = z.unsqueeze(1).repeat(1, self.seq_length, 1)  # (batch_size, seq_length, hidden_dim)\n        output, _ = self.rnn_decode(z)  # (batch_size, seq_length, hidden_dim)\n        return self.output_layer(output)  # (batch_size, seq_length, vocab_size)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        return self.decode(z), mu, logvar\n\n# Loss Function\ndef vae_loss(recon_x, x, mu, logvar):\n    # Reshape recon_x to (batch_size × sequence_length, vocab_size)\n    recon_x = recon_x.view(-1, vocab_size)\n    \n    # Flatten x to (batch_size × sequence_length)\n    x = x.view(-1)\n    \n    # Compute reconstruction loss\n    BCE = nn.CrossEntropyLoss()(recon_x, x)\n    \n    # Compute KL divergence\n    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n    \n    return BCE + KLD\n\n# Load Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntext_data = np.load('/kaggle/input/generated-captions/generated_captions.npy', allow_pickle=True)\n\n# Tokenize and Prepare Dataset\ndef text_to_tensor(texts, tokenizer, seq_length=50):\n    return torch.tensor([\n        tokenizer.encode(text, add_special_tokens=True, padding='max_length', max_length=seq_length, truncation=True)\n        for text in texts\n    ])\n\n# Parameters\nseq_length = 50\nbatch_size = 32\nepochs = 10\nembedding_dim = 256\nlatent_dim = 50\nhidden_dim = 512\n\n# Tokenized text tensor\ntext_tensor = text_to_tensor(text_data, tokenizer, seq_length)\ntrain_loader = DataLoader(text_tensor, batch_size=batch_size, shuffle=True)\n\n# Initialize VAE\nvocab_size = len(tokenizer.vocab)\nvae = VAEText(vocab_size, embedding_dim, latent_dim, hidden_dim, seq_length)\n\n# Move model and data to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvae.to(device)\n\n# Optimizer\noptimizer = optim.Adam(vae.parameters(), lr=1e-3)\n\n# Training Loop with GPU and Progress Bar\nfor epoch in range(epochs):\n    vae.train()\n    total_loss = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n    for batch in progress_bar:\n        batch = batch.to(device)  # Move batch to GPU\n        optimizer.zero_grad()\n        recon_batch, mu, logvar = vae(batch)\n        loss = vae_loss(recon_batch, batch, mu, logvar)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        progress_bar.set_postfix(loss=loss.item())\n    print(f'Epoch {epoch + 1}/{epochs}, Average Loss: {total_loss / len(train_loader)}')\n\n# Save embeddings (latent variables)\nvae.eval()\nembeddings = []\nwith torch.no_grad():\n    for batch in tqdm(train_loader, desc=\"Generating Embeddings\"):\n        batch = batch.to(device)  # Move batch to GPU\n        mu, logvar = vae.encode(batch)\n        embeddings.append(mu)\nembeddings = torch.cat(embeddings, dim=0)\n\n# Save the embeddings\nnp.save('generated_captions_vae_embeddings.npy', embeddings.cpu().numpy())\n\nprint(\"Text embeddings saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T20:43:33.746022Z","iopub.execute_input":"2024-11-23T20:43:33.746448Z","iopub.status.idle":"2024-11-23T20:49:28.388061Z","shell.execute_reply.started":"2024-11-23T20:43:33.746417Z","shell.execute_reply":"2024-11-23T20:49:28.387184Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 517/517 [00:33<00:00, 15.55it/s, loss=1.14] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Average Loss: 1.5028174487257835\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 517/517 [00:33<00:00, 15.34it/s, loss=1.23] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Average Loss: 1.1651920292317521\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 517/517 [00:34<00:00, 15.08it/s, loss=0.992]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Average Loss: 1.1433599894466437\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 517/517 [00:34<00:00, 14.88it/s, loss=1.28] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Average Loss: 1.134742703843624\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 517/517 [00:35<00:00, 14.77it/s, loss=1.13] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Average Loss: 1.1287499858747367\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 517/517 [00:35<00:00, 14.66it/s, loss=1.24] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Average Loss: 1.1251896934536947\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 517/517 [00:35<00:00, 14.57it/s, loss=1.1]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Average Loss: 1.1219714738183602\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 517/517 [00:35<00:00, 14.53it/s, loss=1.19] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Average Loss: 1.1200425624847412\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 517/517 [00:35<00:00, 14.51it/s, loss=1.28] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Average Loss: 1.1184419596448858\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 517/517 [00:35<00:00, 14.48it/s, loss=1.19] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Average Loss: 1.1167916065258492\n","output_type":"stream"},{"name":"stderr","text":"Generating Embeddings: 100%|██████████| 517/517 [00:01<00:00, 373.27it/s]","output_type":"stream"},{"name":"stdout","text":"Text embeddings saved!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":13}]}